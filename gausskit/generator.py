import os
import re
from prompt_toolkit import prompt
from prompt_toolkit.completion import WordCompleter
from prompt_toolkit.completion import WordCompleter, PathCompleter
from gausskit.completions import tab_autocomplete_prompt, HybridCompleter

def read_xyz_file(xyz_path):
    """Reads XYZ coordinates with flexible delimiters and optional atomic index column."""
    try:
        coords = []
        with open(xyz_path, 'r') as f:
            for line in f:
                # Remove whitespace and skip blank lines
                if not line.strip():
                    continue

                # Split by any whitespace, comma, or tab
                parts = re.split(r'[,\s]+', line.strip())

                # Handle formats: [atom, x, y, z] or [atom, _, x, y, z]
                if len(parts) == 4:
                    atom, x, y, z = parts
                elif len(parts) == 5 and parts[1].isdigit():
                    atom, _, x, y, z = parts
                else:
                    print(f"‚ö†Ô∏è Skipping unrecognized line: {line.strip()}")
                    continue

                coords.append(f"{atom} {x} {y} {z}")
        return coords

    except Exception as e:
        print(f"‚ùå Failed to read XYZ file: {e}")
        return []


def create_gaussian_input():
    print("=" * 75)
    print("üìÑ Gaussian Input File Generator")
    print("    - Generates .com file from XYZ and route info.")
    print("    - Includes optional title and basis set footer.")
    print("=" * 75)

    filename = prompt("Enter name for output .com file (without extension): ").strip()
    if not filename:
        print("‚ùå No filename provided.")
        return

    routes = [
        "b3lyp/6-31g(d) opt freq int=superfinegrid scf=(fermi,novaracc)",
        "cam-b3lyp/def2tzvp td(nstates=10) int=superfinegrid scf=(fermi,novaracc)",
        "wb97xd/6-311++g(d,p) opt=tight freq int=superfinegrid scf=(fermi,novaracc)",
        "hf/6-31g sp int=superfinegrid scf=(fermi,novaracc)",
        "m06-2x/cc-pvtz opt freq int=superfinegrid scf=(fermi,novaracc)",
        "pbe0/def2svp opt freq int=superfinegrid scf=(fermi,novaracc)",
        "m062x/def2tzvp ts freq int=superfinegrid scf=(fermi,novaracc)",
        "wb97mv/def2tzvppd sp int=superfinegrid scf=(fermi,novaracc)",
        "b3lyp/def2svp opt freq=noraman int=superfinegrid scf=(fermi,novaracc)",
        "tpssh/cc-pvtz opt=modredundant freq int=superfinegrid scf=(fermi,novaracc)"
    ]
    route_completer = WordCompleter(routes)
    route = prompt("Enter Gaussian route line: ", completer=route_completer).strip()

    title = prompt("Enter title (or press ENTER for default): ").strip() or "Gaussian input file generated by gausspimom"
    charge = prompt("Enter total charge (default 0): ").strip() or "0"
    multiplicity = prompt("Enter multiplicity (default 1): ").strip() or "1"

    xyz_completer = WordCompleter([f for f in os.listdir() if f.endswith('.xyz')])
    xyz_file = prompt("Enter path to XYZ coordinates file: ", completer=xyz_completer).strip()
    coords = read_xyz_file(xyz_file)
    if not coords:
        print("‚ùå No valid coordinates found.")
        return

    basis = prompt("Enter optional basis set footer filename (or press ENTER to skip): ").strip()
    if basis and not os.path.exists(basis):
        print("‚ö†Ô∏è Footer file not found. Ignoring.")
        basis = None

    output_path = filename + ".com"
    with open(output_path, "w") as f:
        f.write(f"%chk={filename}.chk\n")
        f.write(f"#p {route}\n\n")
        f.write(f"{title}\n\n")
        f.write(f"{charge} {multiplicity}\n")
        for line in coords:
            f.write(line + "\n")
        f.write("\n")
        if basis:
            f.write(f"@{basis}\n")

#    print(f"\n‚úÖ Input file created: {output_path}")


    # Extract functional only (e.g., b3lyp from b3lyp/6-31g(d))
    functional_match = re.search(r'([a-zA-Z0-9\-]+)(?=/)', route)
    if functional_match:
        functional = functional_match.group(1)
    else:
        print("‚ö†Ô∏è Could not extract functional from route. Skipping stability job.")
        return

    stab_mode = prompt("Add stability job? [none/link1/separate]: ").strip().lower()
    while stab_mode not in ["none", "link1", "separate"]:
        stab_mode = prompt("Please enter one of [none/link1/separate]: ").strip().lower()

    if stab_mode == "link1":
        with open(output_path, "a") as f:
            f.write("\n--Link1--\n")
            f.write(f"%oldchk={filename}.chk\n")
            f.write(f"%chk={filename}-stab.chk\n")
            f.write(f"#p {functional} guess=read stable=opt chkbasis geom=check\n\n")
            f.write(f"{title} (stability check)\n\n")
            f.write(f"{charge} {multiplicity}\n\n\n")
            if basis:
                f.write(f"@{basis}\n")
        print(f"‚úÖ Stability job added via Link1 in: {output_path}")

    elif stab_mode == "separate":
        stab_path = f"{filename}-stab.com"
        with open(stab_path, "w") as f:
            f.write(f"%oldchk={filename}.chk\n")
            f.write(f"%chk={filename}-stab.chk\n")
            f.write(f"#p {functional} guess=read stable=opt chkbasis geom=check\n\n")
            f.write(f"{title} (stability check)\n\n")
            f.write(f"{charge} {multiplicity}\n\n\n")
            if basis:
                f.write(f"@{basis}\n")
        print(f"‚úÖ Stability job written to separate file: {stab_path}")

    print(f"\n‚úÖ Input file created: {output_path}")

    while True:
        again = prompt("‚ûï Generate another input using this .chk file? [y/N]: ").strip().lower()
        if again != "y":
            break

        new_filename = prompt("Enter new output filename (without extension): ").strip()
        if not new_filename:
            print("‚ùå No filename provided. Aborting follow-up input.")
            break

        new_functional = prompt("Enter new functional (e.g., wb97xd): ").strip()
        new_basis = prompt("Enter new basis set (e.g., def2tzvp): ").strip()
        new_route = f"{new_functional}/{new_basis} guess=read geom=check"

        footer = prompt("Enter optional basis set footer filename (or press ENTER to skip): ").strip()
        if footer and not os.path.exists(footer):
            print("‚ö†Ô∏è Footer file not found. Ignoring.")
            footer = None

        follow_path = new_filename + ".com"
        with open(follow_path, "w") as f:
            f.write(f"%oldchk={filename}.chk\n")
            f.write(f"%chk={new_filename}.chk\n")
            f.write(f"#p {new_route} int=superfinegrid scf=(fermi,novaracc)\n\n")
            f.write(f"{title} (follow-up calculation)\n\n")
            f.write(f"{charge} {multiplicity}\n\n\n")
            if footer:
                f.write(f"@{footer}\n")

        print(f"‚úÖ Follow-up input file created: {follow_path}")
 

def smart_split_basis_sets(basis_input):
    tokens = []
    current = ''
    depth = 0
    for char in basis_input:
        if char == ',' and depth == 0:
            if current.strip():
                tokens.append(current.strip())
                current = ''
        else:
            if char == '(':
                depth += 1
            elif char == ')':
                depth -= 1
            current += char
    if current.strip():
        tokens.append(current.strip())
    return tokens


def clean_label(s):
    # Replace '+' with 'p', remove '-', '(', ')', ',' and all whitespace
    return re.sub(r'[,\s\-\(\)]', '', s.replace('+', 'p'))


def create_benchmark_inputs():
    print("=" * 60)
    print("Benchmark Input Generator: XYZ ‚Üí .com for each functional/basis set")
    print("=" * 60)

    xyz_files = [f for f in os.listdir() if f.endswith(".xyz")]
    file_completer = HybridCompleter([
        WordCompleter(xyz_files),
        PathCompleter(file_filter=lambda f: f.endswith(".xyz"))
    ])

    functional_completer = WordCompleter(DFT_FUNCTIONALS = [
    # General Hybrid and GGA
    'HF', 'BLYP', 'PBE', 'PBE0', 'SCAN', 'TPSSh',
    'B3LYP', 'B3P86', 'B3PW91', 'O3LYP',

    # Dispersion-Corrected Functionals
    'APFD', 'APF', 'wB97XD',

    # Long-Range-Corrected Functionals
    'LC-wHPBE', 'LC-wPBE', 'CAM-B3LYP', 'wB97X', 'wB97',

    # Truhlar Group Functionals
    'MN15', 'M11', 'SOGGA11X', 'N12SX', 'MN12SX',
    'PW6B95', 'PW6B95D3', 'M08HX',
    'M06', 'M06HF', 'M062X', 'M05', 'M052X',

    # PBE Correlation-Based Hybrids
    'PBE1PBE', 'HSEH1PBE', 'OHSE2PBE', 'OHSE1PBE', 'PBEh1PBE',

    # One-Parameter Hybrids
    'B1B95', 'B1LYP', 'mPW1PW91', 'mPW1LYP', 'mPW1PBE', 'mPW3PBE',

    # B97 Revisions
    'B98', 'B971', 'B972',

    # œÑ-dependent hybrids
    'tHCTHhyb', 'BMK',

    # Older/Legacy Hybrids
    'X3LYP', 'HISSbPBE',

    # Half-and-Half Hybrids
    'BHandH', 'BHandHLYP',

    # Exchange-only Functionals
    'PW91', 'mPW', 'G96', 'O', 'TPSS', 'RevTPSS', 'BRx', 'PKZB', 'wPBEh', 'PBEh',

    # Correlation-only Functionals
    'VWN', 'VWN5', 'LYP', 'PL', 'P86', 'PW91', 'B95',
    'TPSS', 'RevTPSS', 'KCIS', 'BRC', 'PKZB',

    # Combined correlation variations
    'VP86', 'V5LYP',

    # Standalone Pure Functionals
    'VSXC', 'HCTH', 'HCTH93', 'HCTH147', 'HCTH407', 'tHCTH',
    'B97D', 'B97D3',
    'M06L', 'SOGGA11', 'M11L', 'MN12L', 'N12', 'MN15L'
    ], ignore_case=True)



    basis_completer = WordCompleter([
    # Minimal and Split-Valence
    'STO-3G', '3-21G', '6-21G', '4-31G',
    '6-31G', '6-31G(d)', '6-31+G(d,p)', '6-31G(d\')', '6-31G(d\',p\')',
    '6-311G', '6-311+G(d)', '6-311+G(d,p)', '6-311++G(d,p)',

    # Dunning correlation-consistent
    'cc-pVDZ', 'cc-pVTZ', 'cc-pVQZ', 'cc-pV5Z', 'cc-pV6Z',
    'aug-cc-pVDZ', 'aug-cc-pVTZ', 'aug-cc-pVQZ', 'aug-cc-pV5Z', 'aug-cc-pV6Z',
    'daug-cc-pVDZ', 'daug-cc-pVTZ', 'spaug-cc-pVDZ', 'jul-cc-pVDZ',
    'Jun-cc-pVDZ', 'May-cc-pVDZ', 'Apr-cc-pVDZ',

    # Ahlrichs/Weigend def2 sets
    'def2-SVP', 'def2-SVPP', 'def2-TZVP', 'def2-TZVPP',
    'def2-QZVP', 'def2-QZVPP',

    # ECP & pseudopotentials
    'LanL2MB', 'LanL2DZ', 'SDD', 'SDDAll',
    'CEP-4G', 'CEP-31G', 'CEP-121G',
    'SHC', 'SEC',

    # D95 and variations
    'D95', 'D95V',

    # Other built-ins and specialty
    'SV', 'SVP', 'TZV', 'TZVP', 'QZVP',
    'MidiX', 'MTSmall', 'CBSB7',
    'EPR-II', 'EPR-III',
    'DGDZVP', 'DGDZVP2', 'DGTZVP',
    'UGBS', 'UGBS1P', 'UGBS2P', 'UGBS3P',
    'UGBS1V', 'UGBS2V', 'UGBS3V',
    'UGBS1O', 'UGBS2O', 'UGBS3O',

    # Generic/genecp
    'gen', 'genecp'
    ], ignore_case=True)


    functionals = prompt("Enter functional(s) (comma-separated): ", completer=functional_completer).strip().split(",")
#    basis_sets = prompt("Enter basis set(s) (comma-separated): ", completer=basis_completer).strip()
    raw_basis_input = prompt("Enter basis set(s) (e.g. 6-31G, 6-31+G(d,p), def2-TZVP): ", completer=basis_completer).strip()
    basis_sets = smart_split_basis_sets(raw_basis_input)
    charge = prompt("Enter charge: (default = 0)").strip() or "0"
    multiplicity = prompt("Enter multiplicity: (default = 1) ").strip() or "1"
    keywords = prompt("Enter route keywords (default: Opt Freq SCF=(fermi, novaracc) int=superfinegrid): ").strip()
    if not keywords:
        keywords = "Opt Freq SCF=(fermi, novaracc) int=superfinegrid"

    basis_sets = [b.strip() for b in basis_sets if b.strip()]
    needs_custom_basis = any(b.lower() in ("gen", "genecp") for b in basis_sets)
    custom_basis_content = ""
    if needs_custom_basis:
        basis_file = tab_autocomplete_prompt("Enter custom basis set file (e.g., .gbs, .txt): ", completer=PathCompleter()).strip()
        if not os.path.exists(basis_file):
            print(f"‚ùå File {basis_file} not found.")
            choice = prompt("Do you want to continue and reference it as @basisset? (y/n): ").strip().lower()
            if not choice.startswith('y'):
                print("‚õî Exiting.")
                return
            else:
                print("‚ö†Ô∏è File will be referenced as @basisset. You must provide the file later.")
                custom_basis_content = f"@{basis_file}\n"
        else:
            custom_basis_content = f"@{basis_file}\n"
    

    for xyz in xyz_files:
        coords = read_xyz_file(xyz)
        coords_str = "\n".join(coords)
        molname = xyz.replace(".xyz", "")

        for func in functionals:
            for basis in basis_sets:
                func_clean = clean_label(func)
                basis_clean = clean_label(basis)
                filename = f"{molname}_{func_clean}_{basis_clean}.com"
                chkname = filename.replace(".com", ".chk")
                stab_chkname = chkname.replace(".chk", "-stab.chk")
        
                method_basis = f"{func.strip()}/{basis.strip()}"
                stability_route = f"#P {method_basis} Geom=AllCheck Guess=Read Stable=Opt SCF=(fermi,novaracc)"
                stability_route_2 = f"#P  {func.strip()} chkbasis  Geom=AllCheck Guess=Read Stable=Opt SCF=(fermi,novaracc)"                
                optfreq_route = f"#P {func.strip()} chkbasis Geom=AllCheck Guess=Read {keywords}"
        
                # Link 0: Initial Stability
                com_content = f"""%Chk={chkname}
#P {method_basis} SCF=(fermi,novaracc) Guess=Mix Stable=Opt

Initial Stability Check for {molname}

{charge} {multiplicity}
{coords_str}
"""
        
                if basis.lower() in ("gen", "genecp"):
                    com_content += f"\n{custom_basis_content.strip()}\n\n"
                else:
                    com_content += "\n"
        
                # Link 1: Optimization + Frequency
                com_content += f"""--Link1--
%Chk={chkname}
{optfreq_route}

Optimization and Frequency

"""
        
                # Link 2: Final Stability Check
                com_content += f"""--Link1--
%OldChk={chkname}
%Chk={stab_chkname}
{stability_route_2}

Final Stability Check



"""
        
                with open(filename, "w") as f:
                    f.write(com_content)
        
                print(f"‚úÖ Generated: {filename}")
         


def create_default_fc_input(gs_base: str, es_base: str) -> str:
    """
    Read gs_base.com and es_base.com, extract:
      - oldchk  ‚Üê from es_base %chk=
      - route   ‚Üê from es_base ‚Äú#P ‚Ä¶‚Äù
      - charge, mult ‚Üê from es_base first ‚ÄúX Y‚Äù line
    and write es_base_fc.com ‚Üí es_base_fc.chk
    Returns the FC base name (without .com).
    """

    def extract_chk(com_path):
        with open(com_path) as f:
            for L in f:
                L = L.strip()
                if L.lower().startswith('%chk='):
                    return L.split('=',1)[1]
        # fallback
        return os.path.splitext(com_path)[0] + '.chk'

    def extract_route(com_path):
        with open(com_path) as f:
            for L in f:
                if L.lower().startswith('#p'):
                    return L.strip()[2:].strip()
        raise RuntimeError(f"No route line (#P) in {com_path}")

    def extract_charge_mult(com_path):
        with open(com_path) as f:
            lines = [l.rstrip() for l in f]
        # skip headers, find title then next nonblank = charge multiplicity
        seen_title = False
        for L in lines:
            if not L.startswith(('%', '#')) and L.strip():
                if not seen_title:
                    seen_title = True
                else:
                    parts = L.split()
                    if len(parts) >= 2:
                        return parts[0], parts[1]
        return "0", "1"

    gs_com = gs_base + '.com'
    es_com = es_base + '.com'

    oldchk_GS = extract_chk(gs_com)
    oldchk_ES = extract_chk(es_com)
    route = extract_route(es_com)
    charge, mult = extract_charge_mult(es_com)

    fc_base = f"{es_base}_fc"
    fc_com  = fc_base + '.com'
    fc_chk  = fc_base + '.chk'

    with open(fc_com, 'w') as out:
        out.write(f"%oldchk={oldchk_GS}\n")
        out.write(f"%chk={fc_chk}\n")
        out.write(f"#P ChkBasis Freq=(ReadFC,FC,ReadFCHT) Geom=Checkpoint NOSYMM Guess=Read\n\n")
        out.write(f"Franck‚ÄìCondon Calculation: {es_base}\n\n")
        out.write(f"{charge} {mult}\n\n")
        out.write("Spectrum=(Broadening=Stick,Lower=-10000.0,Upper=40000.0) temperature=298.15\n\n")
        out.write(f"{oldchk_ES}\n")
    print(f"‚úÖ Default FC input generated: {fc_com}")
    return fc_base



#def write_pimom_input(base_log, alpha_swaps, beta_swaps, charge, multiplicity,
#                      method, footer=None, include_func_in_name=True, custom_oldchk=None):
#    base_name = os.path.splitext(base_log)[0]
#    oldchk = custom_oldchk if custom_oldchk else base_name + ".chk"
#
#    suffix = ""
#    if alpha_swaps:
#        suffix += "-a" + "-".join("_".join(pair) for pair in alpha_swaps)
#    if beta_swaps:
#        suffix += "-b" + "-".join("_".join(pair) for pair in beta_swaps)
#    if include_func_in_name:
#        suffix += f"-{method}"
#
#    outchk = base_name + suffix + ".chk"
#    comfile = base_name + suffix + ".com"
#
#    with open(comfile, "w") as f:
#        f.write(f"%oldchk={oldchk}\n")
#        f.write(f"%chk={outchk}\n")
#        f.write(f"#p {method} scf=(pimom,fermi,novaracc) integral=SuperFineGrid guess=(alter,read) geom=check chkbasis int=noxctest\n\n")
#        f.write("Title Card Required\n\n")
#        f.write(f"{charge} {multiplicity}\n\n")
#
#        for pair in alpha_swaps:
#            f.write(" ".join(pair) + " ! alpha swap\n")
#        if alpha_swaps and beta_swaps:
#            f.write("\n")
#        for pair in beta_swaps:
#            f.write(" ".join(pair) + " ! beta swap\n")
#
#        f.write("\n\n")
#        if footer:
#            f.write(f"@{footer}\n")
#
#    print(f"\n‚úÖ Created file: {comfile}")
#    print(f"   ‚Üí Using %oldchk: {oldchk}")
#    print(f"   ‚Üí Output %chk  : {outchk}")

periodic_table = [
    "",  # index 0 unused
    "H",  "He", "Li", "Be", "B",  "C",  "N",  "O",  "F",  "Ne",
    "Na", "Mg", "Al", "Si", "P",  "S",  "Cl", "Ar", "K",  "Ca",
    "Sc", "Ti", "V",  "Cr", "Mn", "Fe", "Co", "Ni", "Cu", "Zn",
    "Ga", "Ge", "As", "Se", "Br", "Kr", "Rb", "Sr", "Y",  "Zr",
    "Nb", "Mo", "Tc", "Ru", "Rh", "Pd", "Ag", "Cd", "In", "Sn",
    "Sb", "Te", "I",  "Xe", "Cs", "Ba", "La", "Ce", "Pr", "Nd",
    "Pm", "Sm", "Eu", "Gd", "Tb", "Dy", "Ho", "Er", "Tm", "Yb",
    "Lu", "Hf", "Ta", "W",  "Re", "Os", "Ir", "Pt", "Au", "Hg",
    "Tl", "Pb", "Bi", "Po", "At", "Rn", "Fr", "Ra", "Ac", "Th",
    "Pa", "U",  "Np", "Pu", "Am", "Cm", "Bk", "Cf", "Es", "Fm",
    "Md", "No", "Lr", "Rf", "Db", "Sg", "Bh", "Hs", "Mt", "Ds",
    "Rg", "Cn", "Nh", "Fl", "Mc", "Lv", "Ts", "Og"
]


def extract_xyz_from_log(logfile_path, orientation="standard"):
    """
    Extract XYZ coordinates from a Gaussian .log file.
    `orientation` = "standard" or "input"
    Returns: list of strings like ["C 0.000 0.000 0.000", ...]
    """
    if not os.path.exists(logfile_path):
        print(f"‚ùå File not found: {logfile_path}")
        return None

    keyword = "Standard orientation" if orientation == "standard" else "Input orientation"

    with open(logfile_path, 'r', encoding='utf-8', errors='ignore') as f:
        lines = f.readlines()

    block_start = None
    for i, line in enumerate(lines):
        if keyword in line:
            block_start = i
    if block_start is None:
        print(f"‚ùå Could not find orientation: {keyword}")
        return None

    # Skip 5 header lines
    block = lines[block_start+5:]
    xyz_lines = []
    for line in block:
        if "----" in line or len(line.strip()) == 0:
            break
        tokens = line.split()
        atomic_number = int(tokens[1])
        if 0 < atomic_number < len(periodic_table):
            symbol = periodic_table[atomic_number]
        else:
            symbol = "X"
        x, y, z = tokens[3:6]
        xyz_lines.append(f"{symbol} {x} {y} {z}")
    return xyz_lines


def extract_xyz_cli():
    """
    Interactive CLI for extracting XYZ from log files.
    """
    print("=" * 60)
    print("üß™ Gaussian Log to XYZ Extractor")
    print("    - Extracts coordinates from Input or Standard orientation")
    print("    - Can include atom count and comment line")
    print("=" * 60)

    # Ask: all or one
    all_files = prompt("Extract from ALL .log files in this directory? [y/N]: ").strip().lower().startswith("y")
    if all_files:
        log_files = [f for f in os.listdir() if f.endswith(".log")]
    else:
        log_completer = WordCompleter([f for f in os.listdir() if f.endswith('.log')])
        selected = prompt("Select log file: ", completer=log_completer).strip()
        if not os.path.exists(selected):
            print(f"‚ùå File does not exist: {selected}")
            return
        log_files = [selected]

    if not log_files:
        print("‚ùå No .log files found.")
        return

    # Ask: orientation
    orient_choice = prompt("Orientation? [0] Standard  [1] Input (default: 0): ").strip()
    orientation = "input" if orient_choice == "1" else "standard"

    # Ask: format
    fmt_choice = prompt("Output format? [0] Only XYZ lines  [1] Atom count + comment + XYZ (default: 1): ").strip()
    include_count = fmt_choice != "0"

    for log_file in log_files:
        if "Normal termination" not in open(log_file, errors='ignore').read():
            print(f"‚ö†Ô∏è Skipping {log_file}: did not terminate normally.")
            continue

        coords = extract_xyz_from_log(log_file, orientation)
        if not coords:
            print(f"‚ùå Failed to extract from {log_file}")
            continue

        base = os.path.splitext(log_file)[0]
        outname = base + ".xyz"

        with open(outname, "w") as f:
            if include_count:
                f.write(f"{len(coords)}\n")
                f.write(f"{log_file} ‚Äî {orientation} orientation\n")
            for line in coords:
                f.write(line + "\n")

        print(f"‚úÖ Extracted XYZ written to: {outname}")

import os
from prompt_toolkit import prompt
from .utils import MultiPathCompleter  # For tab-completion of file paths

def generate_zmatrix_scan_inputs():
    """
    Generate a series of Gaussian Z-matrix input files by scanning internal variables
    (e.g., B1, A1, D1) defined in a Z-matrix input file.

    ‚ú¶ Input file:
        - Must contain geometry using variables (e.g., R1, A1, D1)
        - Must include assignments like R1=1.9, A1=120.0, etc.
        - ‚ùó Does NOT need to contain the "Variables:" header ‚Äî it is handled internally.

    ‚ú¶ Output:
        - A folder with multiple .com files (one per step)
        - Each .com file contains:
            - Gaussian header (%chk, route, title, charge/mult)
            - Z-matrix geometry (unchanged)
            - The scanned variable values (without "Variables:" line)
        - A scan_summary.txt with details of variable values per step.
    """

    # === 1. Prompt for basic metadata ===
    scan_name = prompt("Enter scan name (e.g., scan1): ").strip() or "scan1"
    input_file = prompt("Enter path to Z-matrix .com file: ", completer=MultiPathCompleter()).strip()
    if not os.path.exists(input_file):
        print("‚ùå File not found.")
        return

    route = prompt("Enter Gaussian route section [# opt b3lyp/def2TZVP]: ").strip() or "# opt b3lyp/def2TZVP"
    charge = prompt("Enter molecular charge [0]: ").strip() or "0"
    mult = prompt("Enter multiplicity [1]: ").strip() or "1"

    # === 2. Prompt for variables to scan ===
    labels = {}  # label ‚Üí {start, step, steps}
    for scan_type in ['Bond', 'Angle', 'Dihedral']:
        label_input = prompt(f"Enter {scan_type} label(s) to scan (e.g., B1,B2), or press Enter to skip: ").strip()
        if label_input:
            start_val = float(prompt(f"Enter starting value for all {scan_type}s: "))
            end_val = float(prompt(f"Enter final value for all {scan_type}s: "))
            step_val = float(prompt(f"Enter step size for all {scan_type}s: "))

            # Auto-calculate number of steps (inclusive)
            n_steps = int(round((end_val - start_val) / step_val)) + 1

            for lbl in label_input.split(','):
                labels[lbl.strip()] = {
                    "start": start_val,
                    "step": step_val,
                    "steps": n_steps
                }

    if not labels:
        print("‚ùå No scan labels provided.")
        return

    # === 3. Validate that all scanned variables use the same number of steps ===
    step_counts = {v['steps'] for v in labels.values()}
    if len(step_counts) != 1:
        print("‚ùå All scanned variables must use the same number of steps. Detected:", step_counts)
        return
    n_steps = step_counts.pop()

    # === 4. Read and split input file ===
    with open(input_file, 'r') as f:
        lines = f.read().splitlines()

    # Find start of variable assignments (e.g., lines like R1=1.9)
    var_start_index = None
    for i, line in enumerate(lines):
        if '=' in line and len(line.strip().split('=')) == 2:
            var_start_index = i
            break

    if var_start_index is None:
        print("‚ùå No variable assignment lines found (e.g., R1=1.90).")
        return

    # Split into geometry and variable lines
    geom_lines = lines[:var_start_index]
    var_lines_original = lines[var_start_index:]

    # === 5. Output directory ===
    scan_dir = f"{scan_name}_scan_inputs"
    os.makedirs(scan_dir, exist_ok=True)

    summary_lines = []

    # === 6. Loop over steps and generate files ===
    for i in range(n_steps):
        # Compute values for this step
        step_vars = {
            lbl: val['start'] + val['step'] * i
            for lbl, val in labels.items()
        }

        # Reconstruct variable assignments
        new_var_lines = []
        for line in var_lines_original:
            parts = line.strip().split('=')
            if len(parts) == 2:
                var_name = parts[0].strip()
                if var_name in step_vars:
                    new_var_lines.append(f"{var_name}={step_vars[var_name]:.6f}")
                else:
                    new_var_lines.append(line.strip())
            else:
                new_var_lines.append(line.strip())

        # Compose full .com file content (no "Variables:" line)
        chk_name = f"{scan_name}_step{i+1:02}.chk"
        out_file = os.path.join(scan_dir, f"{scan_name}_step{i+1:02}.com")
        with open(out_file, 'w') as f:
            f.write(
                f"%chk={chk_name}\n{route}\n\n{scan_name} step {i+1}\n\n"
                f"{charge} {mult}\n"
                + "\n".join(geom_lines).strip() + "\n\n"
                + "\n".join(new_var_lines) + "\n\n"
            )

        # Add to summary log
        summary_lines.append(
            f"{os.path.basename(out_file)}: " +
            ", ".join(f"{k}={v:.6f}" for k, v in step_vars.items())
        )

    # === 7. Write scan summary log ===
    summary_file = os.path.join(scan_dir, "scan_summary.txt")
    with open(summary_file, 'w') as f:
        f.write("Generated scan files:\n\n")
        f.write("\n".join(summary_lines))

    print(f"\n‚úÖ Generated {n_steps} input files in {scan_dir}")
    print(f"üìù Summary written to {summary_file}")

